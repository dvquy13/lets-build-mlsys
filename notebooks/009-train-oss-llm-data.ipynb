{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqM0hhMuCfzn"
   },
   "source": [
    "# Token classification (PyTorch)\n",
    "\n",
    "Original: [HuggingFace Token Classification Fine-tuning Tutorial](https://huggingface.co/learn/nlp-course/en/chapter7/2#defining-the-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n",
      "env: MLFLOW_TRACKING_URI=http://localhost:5002\n"
     ]
    }
   ],
   "source": [
    "# Disable tokenizers warnings when constructing pipelines\n",
    "%env TOKENIZERS_PARALLELISM=false\n",
    "%env MLFLOW_TRACKING_URI=http://localhost:5002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from loguru import logger\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflow/1', creation_time=1720508505405, experiment_id='1', last_update_time=1720508505405, lifecycle_stage='active', name='Cold Embrace - OSS LLM training data', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Cold Embrace - OSS LLM training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aHTw3y28Cfzq"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"dvquys/restaurant-reviews-public-sources\", token=os.environ.get('HUGGINGFACE_READ_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bTLGN83_Cfzq",
    "outputId": "f65a8cb2-2020-4bdb-b19a-cf27d58584c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'Comments', 'tokens', 'ner_tags'],\n",
       "        num_rows: 1590\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['id', 'text', 'Comments', 'tokens', 'ner_tags'],\n",
       "        num_rows: 398\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'text', 'Comments', 'tokens', 'ner_tags'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jB3u92ewCfzq",
    "outputId": "6975e7d5-fc24-4f51-82f3-07c72aa1b8cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good',\n",
       " 'atmosphere',\n",
       " ',',\n",
       " 'combination',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'hottest',\n",
       " 'music',\n",
       " 'dress',\n",
       " 'code',\n",
       " 'is',\n",
       " 'relatively',\n",
       " 'strict',\n",
       " 'except',\n",
       " 'on',\n",
       " 'Fridays',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "i5dJIifACfzq",
    "outputId": "ccb84f29-414f-459a-f12e-b75d6788c0c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 14, 14, 14, 14, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tQ_vPx_zCfzq",
    "outputId": "e1fea2c6-3d40-4af7-a369-b5ac3ebd79e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['O', 'B-AMBIENCE', 'I-AMBIENCE', 'B-BEVERAGE', 'I-BEVERAGE', 'B-FOOD', 'I-FOOD', 'B-LOCATION', 'I-LOCATION', 'B-OVERALL', 'I-OVERALL', 'B-PRICE', 'I-PRICE', 'B-SERVICE', 'I-SERVICE', 'B-STAFF', 'I-STAFF', 'B-VALUE', 'I-VALUE', 'B-VIEW', 'I-VIEW'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
    "ner_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KAIpiIwkCfzq",
    "outputId": "762dcbdc-1346-43ff-bb17-b9b3e5fe84da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-AMBIENCE',\n",
       " 'I-AMBIENCE',\n",
       " 'B-BEVERAGE',\n",
       " 'I-BEVERAGE',\n",
       " 'B-FOOD',\n",
       " 'I-FOOD',\n",
       " 'B-LOCATION',\n",
       " 'I-LOCATION',\n",
       " 'B-OVERALL',\n",
       " 'I-OVERALL',\n",
       " 'B-PRICE',\n",
       " 'I-PRICE',\n",
       " 'B-SERVICE',\n",
       " 'I-SERVICE',\n",
       " 'B-STAFF',\n",
       " 'I-STAFF',\n",
       " 'B-VALUE',\n",
       " 'I-VALUE',\n",
       " 'B-VIEW',\n",
       " 'I-VIEW']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = ner_feature.feature.names\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0xeTcqAMCfzr",
    "outputId": "6ab430b4-8a33-4ec8-c330-dbe9b52fca28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lobster sandwich is     good   and the spaghetti with   Scallops and    Shrimp is     great  . \n",
      "O   B-FOOD  I-FOOD   I-FOOD I-FOOD O   O   B-FOOD    I-FOOD I-FOOD   I-FOOD I-FOOD I-FOOD I-FOOD O \n"
     ]
    }
   ],
   "source": [
    "words = raw_datasets[\"train\"][1][\"tokens\"]\n",
    "labels = raw_datasets[\"train\"][1][\"ner_tags\"]\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "jNTJWPN0Cfzr"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "95af615CCfzr",
    "outputId": "4bb43d70-35a0-4839-c762-7ce7645b4238"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CYeL5AGvCfzr",
    "outputId": "228eccc8-d5c4-41fb-84c4-e82d595e3d17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'The',\n",
       " 'lo',\n",
       " '##bs',\n",
       " '##ter',\n",
       " 'sandwich',\n",
       " 'is',\n",
       " 'good',\n",
       " 'and',\n",
       " 'the',\n",
       " 'spa',\n",
       " '##gh',\n",
       " '##etti',\n",
       " 'with',\n",
       " 'Sc',\n",
       " '##allo',\n",
       " '##ps',\n",
       " 'and',\n",
       " 'Shri',\n",
       " '##mp',\n",
       " 'is',\n",
       " 'great',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(raw_datasets[\"train\"][1][\"tokens\"], is_split_into_words=True)\n",
    "inputs.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Vi7JvpDuCfzr",
    "outputId": "a4a3dd52-90e4-4f59-8bd5-38342d75c8a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " None]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8daUmNWECfzr"
   },
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sJSVH2yPCfzr",
    "outputId": "79074771-98a9-4f45-d458-fa0e3445b8af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5, 6, 6, 6, 0, 0, 5, 6, 6, 6, 6, 6, 6, 0]\n",
      "[-100, 0, 5, 6, 6, 6, 6, 6, 0, 0, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "labels = raw_datasets[\"train\"][1][\"ner_tags\"]\n",
    "word_ids = inputs.word_ids()\n",
    "print(labels)\n",
    "print(align_labels_with_tokens(labels, word_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "dG9xlu1nCfzr"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "suLAZY02Cfzr"
   },
   "outputs": [],
   "source": [
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning with custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qk_H33PDCfzr"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ducHQw9dCfzr",
    "outputId": "b0619874-b40e-4933-ffb3-d6483244ad90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   13,\n",
       "           14,   14,   14,   14,    0,    0,    0,    0,    0, -100, -100, -100],\n",
       "        [-100,    0,    5,    6,    6,    6,    6,    6,    0,    0,    5,    6,\n",
       "            6,    6,    6,    6,    6,    6,    6,    6,    6,    6,    0, -100]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "q1Ev204qCfzr",
    "outputId": "f9591b5d-255e-41f4-de6a-29b33888749e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 14, 14, 14, 14, 0, 0, 0, 0, 0, -100]\n",
      "[-100, 0, 5, 6, 6, 6, 6, 6, 0, 0, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"val\"], collate_fn=data_collator, batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-SERVICE',\n",
       " 'I-SERVICE',\n",
       " 'I-SERVICE',\n",
       " 'I-SERVICE',\n",
       " 'I-SERVICE',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "labels = [label_names[i] for i in labels]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "tgrC6azuCfzu",
    "outputId": "3ec9f22e-0269-4de8-a40d-c46b67a31565"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dvquys/ner-finetune-restaurant-reviews-aspects'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import Repository, get_full_repo_name\n",
    "\n",
    "model_name = \"ner-finetune-restaurant-reviews-aspects\"\n",
    "repo_name = get_full_repo_name(model_name)\n",
    "repo_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import create_repo, repo_exists\n",
    "if not repo_exists(repo_name):\n",
    "    create_repo(repo_name, token=os.environ.get(\"HUGGINGFACE_WRITE_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "AUH5cHetCfzu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvquys/frostmourne/lets-build-mlsys/.venv/lib/python3.9/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "/home/dvquys/frostmourne/lets-build-mlsys/notebooks/ner-finetune-restaurant-reviews-aspects is already a clone of https://huggingface.co/dvquys/ner-finetune-restaurant-reviews-aspects. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "output_dir = model_name\n",
    "repo = Repository(output_dir, clone_from=repo_name, token=os.environ.get(\"HUGGINGFACE_WRITE_TOKEN\"))\n",
    "repo.git_pull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.detach().cpu().clone().numpy()\n",
    "    labels = labels.detach().cpu().clone().numpy()\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return true_labels, true_predictions\n",
    "\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def evaluate_on_evalset(model, evalset, metric):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        model: Transformers model\n",
    "        evalset: HuggingFace dataset (train, eval, test) in Data Loader format\n",
    "        metric: a metric instance initiated by `import evaluate; metric = evaluate.load(\"seqeval\")`\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.eval()\n",
    "    for batch in evalset:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch.to(device))\n",
    "\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        # Necessary to pad predictions and labels for being gathered\n",
    "        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
    "        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "\n",
    "        predictions_gathered = accelerator.gather(predictions)\n",
    "        labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    results = metric.compute()\n",
    "\n",
    "    return results\n",
    "\n",
    "def log_evaluation_metrics(results, prefix='eval', to_mlflow=True, step=None):\n",
    "    results_reformatted = {}\n",
    "    aggregated = dict()\n",
    "    for key, value in results.items():\n",
    "        if key.startswith('overall_'):\n",
    "            assert isinstance(value, float)\n",
    "            metric = key.replace('overall_', '')\n",
    "            metric_key = f\"{prefix}_aggregated_{metric}\"\n",
    "            aggregated[metric] = value\n",
    "            if to_mlflow:\n",
    "                mlflow.log_metric(metric_key, value, step=step)\n",
    "        else:\n",
    "            label = key\n",
    "            for metric, metric_value in value.items():\n",
    "                metric_key = f\"{prefix}_{key}_{metric}\"\n",
    "                if to_mlflow:\n",
    "                    mlflow.log_metric(metric_key, metric_value, step=step)\n",
    "            results_reformatted.update({key: value})\n",
    "    results_reformatted.update({\"aggregated\": aggregated})\n",
    "    results_reformatted_df = pd.DataFrame.from_dict(results_reformatted, orient='index')\n",
    "    logger.info(f\"\\n{results_reformatted_df}\")\n",
    "    return results_reformatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63d11ca37ce4ac9927e73efe800ce9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/597 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9438fa29fce14e68954af8d9820e25ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/597 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvquys/frostmourne/lets-build-mlsys/.venv/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m2024-07-09 16:53:27.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mevaluation on eval set at epoch 0:\u001b[0m\n",
      "\u001b[32m2024-07-09 16:53:28.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_evaluation_metrics\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1m\n",
      "            precision    recall        f1  number  accuracy\n",
      "AMBIENCE     0.278351  0.281250  0.279793    96.0       NaN\n",
      "BEVERAGE     0.000000  0.000000  0.000000     6.0       NaN\n",
      "FOOD         0.398577  0.275862  0.326055   406.0       NaN\n",
      "LOCATION     0.000000  0.000000  0.000000     0.0       NaN\n",
      "OVERALL      0.000000  0.000000  0.000000     0.0       NaN\n",
      "PRICE        0.000000  0.000000  0.000000     0.0       NaN\n",
      "SERVICE      0.256684  0.155844  0.193939   308.0       NaN\n",
      "STAFF        0.000000  0.000000  0.000000     0.0       NaN\n",
      "VALUE        0.000000  0.000000  0.000000     0.0       NaN\n",
      "VIEW         0.000000  0.000000  0.000000     0.0       NaN\n",
      "AGGREGATED   0.289026  0.229167  0.255639     NaN  0.693035\u001b[0m\n",
      "\u001b[32m2024-07-09 16:53:28.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mPushing to HuggingFace Hub...\u001b[0m\n",
      "Several commits (4) will be pushed upstream.\n",
      "/home/dvquys/frostmourne/lets-build-mlsys/.venv/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m2024-07-09 16:53:57.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mevaluation on eval set at epoch 1:\u001b[0m\n",
      "\u001b[32m2024-07-09 16:53:58.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_evaluation_metrics\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1m\n",
      "            precision    recall        f1  number  accuracy\n",
      "AMBIENCE     0.309278  0.277778  0.292683   108.0       NaN\n",
      "BEVERAGE     0.179487  0.125000  0.147368    56.0       NaN\n",
      "FOOD         0.441281  0.284404  0.345886   436.0       NaN\n",
      "LOCATION     0.000000  0.000000  0.000000     0.0       NaN\n",
      "OVERALL      0.000000  0.000000  0.000000     0.0       NaN\n",
      "PRICE        0.100000  0.041667  0.058824    24.0       NaN\n",
      "SERVICE      0.299465  0.213740  0.249443   262.0       NaN\n",
      "STAFF        0.000000  0.000000  0.000000     0.0       NaN\n",
      "VALUE        0.000000  0.000000  0.000000     0.0       NaN\n",
      "VIEW         0.000000  0.000000  0.000000     0.0       NaN\n",
      "AGGREGATED   0.336940  0.246050  0.284410     NaN  0.734691\u001b[0m\n",
      "\u001b[32m2024-07-09 16:53:59.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mPushing to HuggingFace Hub...\u001b[0m\n",
      "Several commits (5) will be pushed upstream.\n",
      "/home/dvquys/frostmourne/lets-build-mlsys/.venv/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m2024-07-09 16:54:28.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mevaluation on eval set at epoch 2:\u001b[0m\n",
      "\u001b[32m2024-07-09 16:54:29.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_evaluation_metrics\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1m\n",
      "            precision    recall        f1  number  accuracy\n",
      "AMBIENCE     0.371134  0.302521  0.333333   119.0       NaN\n",
      "BEVERAGE     0.384615  0.258621  0.309278    58.0       NaN\n",
      "FOOD         0.434164  0.324468  0.371385   376.0       NaN\n",
      "LOCATION     0.000000  0.000000  0.000000     0.0       NaN\n",
      "OVERALL      0.000000  0.000000  0.000000     0.0       NaN\n",
      "PRICE        0.000000  0.000000  0.000000    27.0       NaN\n",
      "SERVICE      0.336898  0.205882  0.255578   306.0       NaN\n",
      "STAFF        0.000000  0.000000  0.000000     0.0       NaN\n",
      "VALUE        0.000000  0.000000  0.000000     0.0       NaN\n",
      "VIEW         0.000000  0.000000  0.000000     0.0       NaN\n",
      "AGGREGATED   0.364760  0.266366  0.307893     NaN   0.73456\u001b[0m\n",
      "\u001b[32m2024-07-09 16:54:30.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mPushing to HuggingFace Hub...\u001b[0m\n",
      "Several commits (6) will be pushed upstream.\n",
      "/home/dvquys/frostmourne/lets-build-mlsys/.venv/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m2024-07-09 16:54:39.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mlog_evaluation_metrics\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1m\n",
      "            precision    recall        f1  number  accuracy\n",
      "AMBIENCE     1.000000  0.333333  0.500000     3.0       NaN\n",
      "FOOD         0.000000  0.000000  0.000000    20.0       NaN\n",
      "LOCATION     0.000000  0.000000  0.000000     0.0       NaN\n",
      "OVERALL      0.000000  0.000000  0.000000     0.0       NaN\n",
      "SERVICE      0.250000  0.166667  0.200000     6.0       NaN\n",
      "VIEW         0.000000  0.000000  0.000000     0.0       NaN\n",
      "AGGREGATED   0.117647  0.068966  0.086957     NaN  0.461538\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"num_train_epochs\", num_train_epochs)\n",
    "    mlflow.log_param(\"num_update_steps_per_epoch\", num_update_steps_per_epoch)\n",
    "    mlflow.log_param(\"num_training_steps\", num_training_steps)\n",
    "    mlflow.log_param(\"learning_rate\", optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "    \n",
    "    for epoch in range(num_train_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        for batch in train_dataloader:\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            accelerator.backward(loss)\n",
    "    \n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "    \n",
    "        mlflow.log_metric(\"train_loss\", loss.item(), step=epoch)\n",
    "    \n",
    "        # Evaluation\n",
    "        results = evaluate_on_evalset(model, eval_dataloader, metric)\n",
    "        logger.info(\n",
    "            f\"evaluation on eval set at epoch {epoch}:\"\n",
    "        )\n",
    "        log_evaluation_metrics(results, prefix='eval', step=epoch)\n",
    "    \n",
    "        # Save and upload\n",
    "        accelerator.wait_for_everyone()\n",
    "        unwrapped_model = accelerator.unwrap_model(model)\n",
    "        unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "        if accelerator.is_main_process:\n",
    "            tokenizer.save_pretrained(output_dir)\n",
    "            logger.info(f\"Pushing to HuggingFace Hub...\")\n",
    "            repo.push_to_hub(\n",
    "                commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "            )\n",
    "    \n",
    "    test_dataloader = DataLoader(\n",
    "        tokenized_datasets[\"test\"], collate_fn=data_collator, batch_size=8\n",
    "    )\n",
    "    results = evaluate_on_evalset(model, test_dataloader, metric)\n",
    "    log_evaluation_metrics(results, prefix='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'SERVICE',\n",
       "  'score': 0.61868334,\n",
       "  'word': 'friendly staff',\n",
       "  'start': 15,\n",
       "  'end': 29},\n",
       " {'entity_group': 'SERVICE',\n",
       "  'score': 0.28880322,\n",
       "  'word': 'celebration',\n",
       "  'start': 43,\n",
       "  'end': 54}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Local model\n",
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=output_dir, aggregation_strategy=\"simple\", device='cuda'\n",
    ")\n",
    "token_classifier('Delicious food friendly staff and one good celebration!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Token classification (PyTorch)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
