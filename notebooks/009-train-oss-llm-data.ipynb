{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqM0hhMuCfzn"
   },
   "source": [
    "# Token classification (PyTorch)\n",
    "\n",
    "Original: [HuggingFace Token Classification Fine-tuning Tutorial](https://huggingface.co/learn/nlp-course/en/chapter7/2#defining-the-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n",
      "env: MLFLOW_TRACKING_URI=http://localhost:5002\n"
     ]
    }
   ],
   "source": [
    "# Disable tokenizers warnings when constructing pipelines\n",
    "%env TOKENIZERS_PARALLELISM=false\n",
    "%env MLFLOW_TRACKING_URI=http://localhost:5002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from loguru import logger\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflow/1', creation_time=1720508505405, experiment_id='1', last_update_time=1720508505405, lifecycle_stage='active', name='Cold Embrace - OSS LLM training data', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Cold Embrace - OSS LLM training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aHTw3y28Cfzq"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"dvquys/restaurant-reviews-public-sources\", token=os.environ.get('HUGGINGFACE_READ_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bTLGN83_Cfzq",
    "outputId": "f65a8cb2-2020-4bdb-b19a-cf27d58584c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'Comments', 'tokens', 'ner_tags'],\n",
       "        num_rows: 1590\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['id', 'text', 'Comments', 'tokens', 'ner_tags'],\n",
       "        num_rows: 398\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'text', 'Comments', 'tokens', 'ner_tags'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jB3u92ewCfzq",
    "outputId": "6975e7d5-fc24-4f51-82f3-07c72aa1b8cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good',\n",
       " 'atmosphere',\n",
       " ',',\n",
       " 'combination',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'hottest',\n",
       " 'music',\n",
       " 'dress',\n",
       " 'code',\n",
       " 'is',\n",
       " 'relatively',\n",
       " 'strict',\n",
       " 'except',\n",
       " 'on',\n",
       " 'Fridays',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "i5dJIifACfzq",
    "outputId": "ccb84f29-414f-459a-f12e-b75d6788c0c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 14, 14, 14, 14, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tQ_vPx_zCfzq",
    "outputId": "e1fea2c6-3d40-4af7-a369-b5ac3ebd79e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['O', 'B-AMBIENCE', 'I-AMBIENCE', 'B-BEVERAGE', 'I-BEVERAGE', 'B-FOOD', 'I-FOOD', 'B-LOCATION', 'I-LOCATION', 'B-OVERALL', 'I-OVERALL', 'B-PRICE', 'I-PRICE', 'B-SERVICE', 'I-SERVICE', 'B-STAFF', 'I-STAFF', 'B-VALUE', 'I-VALUE', 'B-VIEW', 'I-VIEW'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
    "ner_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KAIpiIwkCfzq",
    "outputId": "762dcbdc-1346-43ff-bb17-b9b3e5fe84da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-AMBIENCE',\n",
       " 'I-AMBIENCE',\n",
       " 'B-BEVERAGE',\n",
       " 'I-BEVERAGE',\n",
       " 'B-FOOD',\n",
       " 'I-FOOD',\n",
       " 'B-LOCATION',\n",
       " 'I-LOCATION',\n",
       " 'B-OVERALL',\n",
       " 'I-OVERALL',\n",
       " 'B-PRICE',\n",
       " 'I-PRICE',\n",
       " 'B-SERVICE',\n",
       " 'I-SERVICE',\n",
       " 'B-STAFF',\n",
       " 'I-STAFF',\n",
       " 'B-VALUE',\n",
       " 'I-VALUE',\n",
       " 'B-VIEW',\n",
       " 'I-VIEW']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = ner_feature.feature.names\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0xeTcqAMCfzr",
    "outputId": "6ab430b4-8a33-4ec8-c330-dbe9b52fca28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lobster sandwich is     good   and the spaghetti with   Scallops and    Shrimp is     great  . \n",
      "O   B-FOOD  I-FOOD   I-FOOD I-FOOD O   O   B-FOOD    I-FOOD I-FOOD   I-FOOD I-FOOD I-FOOD I-FOOD O \n"
     ]
    }
   ],
   "source": [
    "words = raw_datasets[\"train\"][1][\"tokens\"]\n",
    "labels = raw_datasets[\"train\"][1][\"ner_tags\"]\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "jNTJWPN0Cfzr"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "95af615CCfzr",
    "outputId": "4bb43d70-35a0-4839-c762-7ce7645b4238"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CYeL5AGvCfzr",
    "outputId": "228eccc8-d5c4-41fb-84c4-e82d595e3d17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'The',\n",
       " 'lo',\n",
       " '##bs',\n",
       " '##ter',\n",
       " 'sandwich',\n",
       " 'is',\n",
       " 'good',\n",
       " 'and',\n",
       " 'the',\n",
       " 'spa',\n",
       " '##gh',\n",
       " '##etti',\n",
       " 'with',\n",
       " 'Sc',\n",
       " '##allo',\n",
       " '##ps',\n",
       " 'and',\n",
       " 'Shri',\n",
       " '##mp',\n",
       " 'is',\n",
       " 'great',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(raw_datasets[\"train\"][1][\"tokens\"], is_split_into_words=True)\n",
    "inputs.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Vi7JvpDuCfzr",
    "outputId": "a4a3dd52-90e4-4f59-8bd5-38342d75c8a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " None]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8daUmNWECfzr"
   },
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sJSVH2yPCfzr",
    "outputId": "79074771-98a9-4f45-d458-fa0e3445b8af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5, 6, 6, 6, 0, 0, 5, 6, 6, 6, 6, 6, 6, 0]\n",
      "[-100, 0, 5, 6, 6, 6, 6, 6, 0, 0, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "labels = raw_datasets[\"train\"][1][\"ner_tags\"]\n",
    "word_ids = inputs.word_ids()\n",
    "print(labels)\n",
    "print(align_labels_with_tokens(labels, word_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "dG9xlu1nCfzr"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "suLAZY02Cfzr"
   },
   "outputs": [],
   "source": [
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning with custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qk_H33PDCfzr"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ducHQw9dCfzr",
    "outputId": "b0619874-b40e-4933-ffb3-d6483244ad90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   13,\n",
       "           14,   14,   14,   14,    0,    0,    0,    0,    0, -100, -100, -100],\n",
       "        [-100,    0,    5,    6,    6,    6,    6,    6,    0,    0,    5,    6,\n",
       "            6,    6,    6,    6,    6,    6,    6,    6,    6,    6,    0, -100]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "q1Ev204qCfzr",
    "outputId": "f9591b5d-255e-41f4-de6a-29b33888749e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 14, 14, 14, 14, 0, 0, 0, 0, 0, -100]\n",
      "[-100, 0, 5, 6, 6, 6, 6, 6, 0, 0, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"val\"], collate_fn=data_collator, batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-SERVICE',\n",
       " 'I-SERVICE',\n",
       " 'I-SERVICE',\n",
       " 'I-SERVICE',\n",
       " 'I-SERVICE',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "labels = [label_names[i] for i in labels]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "tgrC6azuCfzu",
    "outputId": "3ec9f22e-0269-4de8-a40d-c46b67a31565"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dvquys/ner-finetune-restaurant-reviews-aspects'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import Repository, get_full_repo_name\n",
    "\n",
    "model_name = \"ner-finetune-restaurant-reviews-aspects\"\n",
    "repo_name = get_full_repo_name(model_name)\n",
    "repo_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import create_repo, repo_exists\n",
    "if not repo_exists(repo_name):\n",
    "    create_repo(repo_name, token=os.environ.get(\"HUGGINGFACE_WRITE_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "AUH5cHetCfzu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvquys/frostmourne/lets-build-mlsys/.venv/lib/python3.9/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "/home/dvquys/frostmourne/lets-build-mlsys/notebooks/ner-finetune-restaurant-reviews-aspects is already a clone of https://huggingface.co/dvquys/ner-finetune-restaurant-reviews-aspects. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "output_dir = model_name\n",
    "repo = Repository(output_dir, clone_from=repo_name, token=os.environ.get(\"HUGGINGFACE_WRITE_TOKEN\"))\n",
    "repo.git_pull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.detach().cpu().clone().numpy()\n",
    "    labels = labels.detach().cpu().clone().numpy()\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return true_labels, true_predictions\n",
    "\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_evalset(model, evalset, metric):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        model: Transformers model\n",
    "        evalset: HuggingFace dataset (train, eval, test) in Data Loader format\n",
    "        metric: a metric instance initiated by `import evaluate; metric = evaluate.load(\"seqeval\")`\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.eval()\n",
    "    for batch in evalset:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch.to(device))\n",
    "\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        # Necessary to pad predictions and labels for being gathered\n",
    "        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
    "        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "\n",
    "        predictions_gathered = accelerator.gather(predictions)\n",
    "        labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    results = metric.compute()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0493b93d097646e891d4f94701d6f7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/597 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9714432b194a4ca375e22b09ffbf12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/597 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvquys/frostmourne/lets-build-mlsys/.venv/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m2024-07-09 15:21:27.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mevaluation on eval set at epoch 0:\u001b[0m\n",
      "\u001b[32m2024-07-09 15:21:27.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1m{'precision': 0.2828438948995363, 'recall': 0.1986970684039088, 'f1': 0.2334183673469388, 'accuracy': 0.6838370565045992}\u001b[0m\n",
      "\u001b[32m2024-07-09 15:21:28.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mPushing to HuggingFace Hub...\u001b[0m\n",
      "Several commits (7) will be pushed upstream.\n",
      "/home/dvquys/frostmourne/lets-build-mlsys/.venv/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m2024-07-09 15:21:57.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mevaluation on eval set at epoch 1:\u001b[0m\n",
      "\u001b[32m2024-07-09 15:21:57.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1m{'precision': 0.3261205564142195, 'recall': 0.22470713525026625, 'f1': 0.266078184110971, 'accuracy': 0.7127463863337714}\u001b[0m\n",
      "\u001b[32m2024-07-09 15:21:57.929\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mPushing to HuggingFace Hub...\u001b[0m\n",
      "Several commits (8) will be pushed upstream.\n",
      "/home/dvquys/frostmourne/lets-build-mlsys/.venv/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m2024-07-09 15:22:26.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mevaluation on eval set at epoch 2:\u001b[0m\n",
      "\u001b[32m2024-07-09 15:22:26.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1m{'precision': 0.366306027820711, 'recall': 0.25, 'f1': 0.29717868338557996, 'accuracy': 0.7229960578186596}\u001b[0m\n",
      "\u001b[32m2024-07-09 15:22:27.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mPushing to HuggingFace Hub...\u001b[0m\n",
      "Several commits (9) will be pushed upstream.\n",
      "/home/dvquys/frostmourne/lets-build-mlsys/.venv/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\u001b[32m2024-07-09 15:22:36.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mtest set evaluation:\u001b[0m\n",
      "\u001b[32m2024-07-09 15:22:36.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m62\u001b[0m - \u001b[1m{'precision': '0.06', 'recall': '0.03', 'f1': '0.04', 'accuracy': '0.53'}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "mlflow.start_run()\n",
    "# Log parameters\n",
    "mlflow.log_param(\"num_train_epochs\", num_train_epochs)\n",
    "mlflow.log_param(\"num_update_steps_per_epoch\", num_update_steps_per_epoch)\n",
    "mlflow.log_param(\"num_training_steps\", num_training_steps)\n",
    "mlflow.log_param(\"learning_rate\", optimizer.param_groups[0]['lr'])\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    mlflow.log_metric(\"train_loss\", loss.item(), step=epoch)\n",
    "\n",
    "    # Evaluation\n",
    "    results = evaluate_on_evalset(model, eval_dataloader, metric)\n",
    "    logger.info(\n",
    "        f\"evaluation on eval set at epoch {epoch}:\"\n",
    "    )\n",
    "    logger.info(\n",
    "        {\n",
    "            key: f\"{results[f'overall_{key}']:,.2f}\"\n",
    "            for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Log evaluation metrics\n",
    "    for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]:\n",
    "        mlflow.log_metric(f\"eval_{key}\", results[f\"overall_{key}\"], step=epoch)\n",
    "\n",
    "    # Save and upload\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        logger.info(f\"Pushing to HuggingFace Hub...\")\n",
    "        repo.push_to_hub(\n",
    "            commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "        )\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"test\"], collate_fn=data_collator, batch_size=8\n",
    ")\n",
    "results = evaluate_on_evalset(model, test_dataloader, metric)\n",
    "logger.info(\"test set evaluation:\")\n",
    "logger.info(\n",
    "    {\n",
    "        key: f\"{results[f'overall_{key}']:,.2f}\"\n",
    "        for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
    "    },\n",
    ")\n",
    "for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]:\n",
    "    mlflow.log_metric(f\"test_{key}\", results[f\"overall_{key}\"], step=epoch)\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'AMBIENCE',\n",
       "  'score': 0.68482435,\n",
       "  'word': 'place was nice and calm',\n",
       "  'start': 4,\n",
       "  'end': 27}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Local model\n",
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=output_dir, aggregation_strategy=\"simple\", device='cuda'\n",
    ")\n",
    "token_classifier('The place was nice and calm.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Token classification (PyTorch)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
